#read RDS file for verification
Merged_Data_Long=readRDS("Merged_Data_LongRDS")
str(Merged_Data_Long)
#save as CSV file and view for verification
write.csv(Merged_Data_Long,"Merged_Data_Long2.csv", row.names=FALSE)
Merged_Data_Long=read.csv("Merged_Data_Long2.csv")
str(Merged_Data_Long)
#EXERCISE 1
rm(list = ls())#start fresh
options(repos = c(CRAN = "https://cran.rstudio.com/"))#needed this command to prevent the knitting function from failing
#install per directions from tutorial
install.packages('rio')
#read the files from HW3 for exercise
Infant_Mortality=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Infant_Mortality_Formatted2.csv")
Life_Expectantcy=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Life_Expectantcy_Formatted2.csv")
Maternal=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Maternal_Formatted2.csv")
#display column names to verify that files are being read successfully.  Also confirming data types as part of this chunk.
names(Infant_Mortality)
names(Life_Expectantcy)
names(Maternal)
str(Infant_Mortality)
str(Life_Expectantcy)
str(Maternal)
#merging all three data frames together. Need a primary key for this to succeed, so using country. The merge needs to be completed in two steps, because you can only merge two at a time.
merged_data <- merge(Infant_Mortality, Life_Expectantcy, by = "Country")
final_merged_data <- merge(merged_data, Maternal, by = "Country")
#showing column names to see results.
names(final_merged_data)
# Remove the 'Region.x' and 'Region.y' columns from final_merged_data
final_merged_data <- subset(final_merged_data, select = -c(Region.x, Region.y))
#this code chunk is to reorder the column names so that Region is next to Country.
# Get the current column names
current_cols <- names(final_merged_data)
# Identify the target column to move ('Region')
region_col <- "Region"
# Identify the column 'Country' after which 'Region' should be placed
country_col <- "Country"
# Create a new order for the columns
new_col_order <- c(country_col, region_col, setdiff(current_cols, c(country_col, region_col)))
# Reorder the DataFrame columns
final_merged_data <- final_merged_data[, new_col_order]
# Display head of data frame to verify changes
head(final_merged_data,20)
#saving as an RDS file
saveRDS(final_merged_data,"Final_Merged_Data_HW4")
#reading to verify
Final_Merged_Data_HW4RDS=readRDS("Final_Merged_Data_HW4")
str(Final_Merged_Data_HW4RDS)
#saving as CSV file and reading to verify
write.csv(final_merged_data,"Final_Merged_Data2.csv", row.names=FALSE)
Final_Merged_Data2=read.csv("Final_Merged_Data2.csv")
str(Final_Merged_Data2)
#EXERCISE 2
#read the data file for the next exercise
read=final_merged_data
#provide data types to confirm file is still being read correctly.
str(final_merged_data)
#show first 20 rows of data for further verfication.
head(final_merged_data,20)
#downloading dplyr library needed for data aggregation
library(dplyr)
# Group the data by 'Region' and calculate the sum of numerical columns.  I chose average because it is the variable that makes the most sense in looking at the data set.
aggregated_data_by_region <- final_merged_data %>%
group_by(Region) %>%
summarise(
Average_Infant_Deaths_Per_1K = mean(Infant_Deaths_Per_1K, na.rm = TRUE),
Average_Expected_Years_To_Live = mean(Expected_Years_To_Live, na.rm = TRUE),
Total_Deaths_Per_100K_Live_Births = mean(Deaths_Per_100K_Live_Births, na.rm = TRUE)
)
aggregated_data_by_region$Average_Expected_Years_To_Live <- as.integer(aggregated_data_by_region$Average_Expected_Years_To_Live) #this code is to convert the string associated with average expected years to live to an integer. Allowing a double makes the results hard to read.
str(aggregated_data_by_region)
head(aggregated_data_by_region,20) #showing the head to verify - first 20 rows
#save as RDS file
saveRDS(aggregated_data_by_region,"aggregated_data_by_regionwHW4")
#read the file to verify
aggregated_data_by_region=readRDS("aggregated_data_by_regionwHW4")
str(aggregated_data_by_region)
#save as CSV and verify per homework instructions
write.csv(aggregated_data_by_region,"aggregated_data_by_region2.csv", row.names=FALSE)
aggregated_data_by_region=read.csv("aggregated_data_by_region2.csv")
str(aggregated_data_by_region)
#EXERCISE 3
#reading the data frame from exercise 1.
read=final_merged_data
#formatted view for verification that the data continues to display as expected.
head(final_merged_data,20)
#code chunk to convert the data from wide to long format.  Combining all non-region/country columns into a 'Death Type' column.  Values column is designated as "Deaths", which are the number of deaths per each death type.
Merged_Data_Long=tidyr::pivot_longer(data=final_merged_data,
cols=c(Infant_Deaths_Per_1K, Expected_Years_To_Live, Deaths_Per_100K_Live_Births),
names_to = "Infant_LifeExp_Maternal",
values_to = "Data")
#remove the region column
Merged_Data_Long <- subset(Merged_Data_Long, select = -c(Region))
head(Merged_Data_Long,20) #Show head for further verification - first 20 rows
#save as RDS file.
saveRDS(Merged_Data_Long,"Merged_Data_LongRDS")
#read RDS file for verification
Merged_Data_Long=readRDS("Merged_Data_LongRDS")
str(Merged_Data_Long)
#save as CSV file and view for verification
write.csv(Merged_Data_Long,"Merged_Data_Long2.csv", row.names=FALSE)
Merged_Data_Long=read.csv("Merged_Data_Long2.csv")
str(Merged_Data_Long)
#EXERCISE 1
rm(list = ls())#start fresh
options(repos = c(CRAN = "https://cran.rstudio.com/"))#needed this command to prevent the knitting function from failing
#install per directions from tutorial
install.packages('rio')
#read the files from HW3 for exercise
Infant_Mortality=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Infant_Mortality_Formatted2.csv")
Life_Expectantcy=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Life_Expectantcy_Formatted2.csv")
Maternal=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Maternal_Formatted2.csv")
#display column names to verify that files are being read successfully.  Also confirming data types as part of this chunk.
names(Infant_Mortality)
names(Life_Expectantcy)
names(Maternal)
str(Infant_Mortality)
str(Life_Expectantcy)
str(Maternal)
#merging all three data frames together. Need a primary key for this to succeed, so using country. The merge needs to be completed in two steps, because you can only merge two at a time.
merged_data <- merge(Infant_Mortality, Life_Expectantcy, by = "Country")
final_merged_data <- merge(merged_data, Maternal, by = "Country")
#showing column names to see results.
names(final_merged_data)
# Remove the 'Region.x' and 'Region.y' columns from final_merged_data
final_merged_data <- subset(final_merged_data, select = -c(Region.x, Region.y))
#this code chunk is to reorder the column names so that Region is next to Country.
# Get the current column names
current_cols <- names(final_merged_data)
# Identify the target column to move ('Region')
region_col <- "Region"
# Identify the column 'Country' after which 'Region' should be placed
country_col <- "Country"
# Create a new order for the columns
new_col_order <- c(country_col, region_col, setdiff(current_cols, c(country_col, region_col)))
# Reorder the DataFrame columns
final_merged_data <- final_merged_data[, new_col_order]
# Display head of data frame to verify changes
head(final_merged_data,20)
#saving as an RDS file
saveRDS(final_merged_data,"Final_Merged_Data_HW4")
#reading to verify
Final_Merged_Data_HW4RDS=readRDS("Final_Merged_Data_HW4")
str(Final_Merged_Data_HW4RDS)
#saving as CSV file and reading to verify
write.csv(final_merged_data,"Final_Merged_Data2.csv", row.names=FALSE)
Final_Merged_Data2=read.csv("Final_Merged_Data2.csv")
str(Final_Merged_Data2)
#EXERCISE 2
#read the data file for the next exercise
read=final_merged_data
#provide data types to confirm file is still being read correctly.
str(final_merged_data)
#show first 20 rows of data for further verfication.
head(final_merged_data,20)
#downloading dplyr library needed for data aggregation
library(dplyr)
# Group the data by 'Region' and calculate the sum of numerical columns.  I chose average because it is the variable that makes the most sense in looking at the data set.
aggregated_data_by_region <- final_merged_data %>%
group_by(Region) %>%
summarise(
Average_Infant_Deaths_Per_1K = mean(Infant_Deaths_Per_1K, na.rm = TRUE),
Average_Expected_Years_To_Live = mean(Expected_Years_To_Live, na.rm = TRUE),
Total_Deaths_Per_100K_Live_Births = mean(Deaths_Per_100K_Live_Births, na.rm = TRUE)
)
aggregated_data_by_region$Average_Expected_Years_To_Live <- as.integer(aggregated_data_by_region$Average_Expected_Years_To_Live)
aggregated_data_by_region$Average_Infant_Deaths_Per_1K <- as.integer(aggregated_data_by_region$Average_Infant_Deaths_Per_1K)
aggregated_data_by_region$Average_Total_Deaths_Per_100K_Live_Births <- as.integer(aggregated_data_by_region$Total_Deaths_Per_100K_Live_Births)
#this code is to convert the string associated with average expected years to live to an integer, which will make that part of the data frame easier to read.
str(aggregated_data_by_region) #confirms that the above change properly executed.
head(aggregated_data_by_region,20) #showing the head to verify - first 20 rows
#save as RDS file
saveRDS(aggregated_data_by_region,"aggregated_data_by_regionwHW4")
#read the file to verify
aggregated_data_by_region=readRDS("aggregated_data_by_regionwHW4")
str(aggregated_data_by_region)
#save as CSV and verify per homework instructions
write.csv(aggregated_data_by_region,"aggregated_data_by_region2.csv", row.names=FALSE)
aggregated_data_by_region=read.csv("aggregated_data_by_region2.csv")
str(aggregated_data_by_region)
#EXERCISE 3
#reading the data frame from exercise 1.
read=final_merged_data
#formatted view for verification that the data continues to display as expected.
head(final_merged_data,20)
#code chunk to convert the data from wide to long format.  Combining all non-region/country columns into a 'Death Type' column.  Values column is designated as "Deaths", which are the number of deaths per each death type.
Merged_Data_Long=tidyr::pivot_longer(data=final_merged_data,
cols=c(Infant_Deaths_Per_1K, Expected_Years_To_Live, Deaths_Per_100K_Live_Births),
names_to = "Infant_LifeExp_Maternal",
values_to = "Data")
#remove the region column
Merged_Data_Long <- subset(Merged_Data_Long, select = -c(Region))
head(Merged_Data_Long,20) #Show head for further verification - first 20 rows
#save as RDS file.
saveRDS(Merged_Data_Long,"Merged_Data_LongRDS")
#read RDS file for verification
Merged_Data_Long=readRDS("Merged_Data_LongRDS")
str(Merged_Data_Long)
#save as CSV file and view for verification
write.csv(Merged_Data_Long,"Merged_Data_Long2.csv", row.names=FALSE)
Merged_Data_Long=read.csv("Merged_Data_Long2.csv")
str(Merged_Data_Long)
#EXERCISE 1
rm(list = ls())#start fresh
options(repos = c(CRAN = "https://cran.rstudio.com/"))#needed this command to prevent the knitting function from failing
#install per directions from tutorial
install.packages('rio')
#read the files from HW3 for exercise
Infant_Mortality=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Infant_Mortality_Formatted2.csv")
Life_Expectantcy=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Life_Expectantcy_Formatted2.csv")
Maternal=read.csv("https://raw.githubusercontent.com/Fundamentals-Josh/hw4/refs/heads/main/HW%203%20files%20to%20be%20used%20for%20hw4/Maternal_Formatted2.csv")
#display column names to verify that files are being read successfully.  Also confirming data types as part of this chunk.
names(Infant_Mortality)
names(Life_Expectantcy)
names(Maternal)
str(Infant_Mortality)
str(Life_Expectantcy)
str(Maternal)
#merging all three data frames together. Need a primary key for this to succeed, so using country. The merge needs to be completed in two steps, because you can only merge two at a time.
merged_data <- merge(Infant_Mortality, Life_Expectantcy, by = "Country")
final_merged_data <- merge(merged_data, Maternal, by = "Country")
#showing column names to see results.
names(final_merged_data)
# Remove the 'Region.x' and 'Region.y' columns from final_merged_data
final_merged_data <- subset(final_merged_data, select = -c(Region.x, Region.y))
#this code chunk is to reorder the column names so that Region is next to Country.
# Get the current column names
current_cols <- names(final_merged_data)
# Identify the target column to move ('Region')
region_col <- "Region"
# Identify the column 'Country' after which 'Region' should be placed
country_col <- "Country"
# Create a new order for the columns
new_col_order <- c(country_col, region_col, setdiff(current_cols, c(country_col, region_col)))
# Reorder the DataFrame columns
final_merged_data <- final_merged_data[, new_col_order]
# Display head of data frame to verify changes
head(final_merged_data,20)
#saving as an RDS file
saveRDS(final_merged_data,"Final_Merged_Data_HW4")
#reading to verify
Final_Merged_Data_HW4RDS=readRDS("Final_Merged_Data_HW4")
str(Final_Merged_Data_HW4RDS)
#saving as CSV file and reading to verify
write.csv(final_merged_data,"Final_Merged_Data2.csv", row.names=FALSE)
Final_Merged_Data2=read.csv("Final_Merged_Data2.csv")
str(Final_Merged_Data2)
#EXERCISE 2
#read the data file for the next exercise
read=final_merged_data
#provide data types to confirm file is still being read correctly.
str(final_merged_data)
#show first 20 rows of data for further verfication.
head(final_merged_data,20)
#downloading dplyr library needed for data aggregation
library(dplyr)
# Group the data by 'Region' and calculate the sum of numerical columns.  I chose average because it is the variable that makes the most sense in looking at the data set.
aggregated_data_by_region <- final_merged_data %>%
group_by(Region) %>%
summarise(
Average_Infant_Deaths_Per_1K = mean(Infant_Deaths_Per_1K, na.rm = TRUE),
Average_Expected_Years_To_Live = mean(Expected_Years_To_Live, na.rm = TRUE),
Total_Deaths_Per_100K_Live_Births = mean(Deaths_Per_100K_Live_Births, na.rm = TRUE)
)
aggregated_data_by_region$Average_Expected_Years_To_Live <- as.integer(aggregated_data_by_region$Average_Expected_Years_To_Live)
aggregated_data_by_region$Average_Infant_Deaths_Per_1K <- as.integer(aggregated_data_by_region$Average_Infant_Deaths_Per_1K)
aggregated_data_by_region$Total_Deaths_Per_100K_Live_Births <- as.integer(aggregated_data_by_region$Total_Deaths_Per_100K_Live_Births)
#this code is to convert the string associated with average expected years to live to an integer, which will make that part of the data frame easier to read.
str(aggregated_data_by_region) #confirms that the above change properly executed.
head(aggregated_data_by_region,20) #showing the head to verify - first 20 rows
#save as RDS file
saveRDS(aggregated_data_by_region,"aggregated_data_by_regionwHW4")
#read the file to verify
aggregated_data_by_region=readRDS("aggregated_data_by_regionwHW4")
str(aggregated_data_by_region)
#save as CSV and verify per homework instructions
write.csv(aggregated_data_by_region,"aggregated_data_by_region2.csv", row.names=FALSE)
aggregated_data_by_region=read.csv("aggregated_data_by_region2.csv")
str(aggregated_data_by_region)
#EXERCISE 3
#reading the data frame from exercise 1.
read=final_merged_data
#formatted view for verification that the data continues to display as expected.
head(final_merged_data,20)
#code chunk to convert the data from wide to long format.  Combining all non-region/country columns into a 'Death Type' column.  Values column is designated as "Deaths", which are the number of deaths per each death type.
Merged_Data_Long=tidyr::pivot_longer(data=final_merged_data,
cols=c(Infant_Deaths_Per_1K, Expected_Years_To_Live, Deaths_Per_100K_Live_Births),
names_to = "Infant_LifeExp_Maternal",
values_to = "Data")
#remove the region column
Merged_Data_Long <- subset(Merged_Data_Long, select = -c(Region))
head(Merged_Data_Long,20) #Show head for further verification - first 20 rows
#save as RDS file.
saveRDS(Merged_Data_Long,"Merged_Data_LongRDS")
#read RDS file for verification
Merged_Data_Long=readRDS("Merged_Data_LongRDS")
str(Merged_Data_Long)
#save as CSV file and view for verification
write.csv(Merged_Data_Long,"Merged_Data_Long2.csv", row.names=FALSE)
Merged_Data_Long=read.csv("Merged_Data_Long2.csv")
str(Merged_Data_Long)
rm(list = ls())
###
git=''
org=''
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/Class_5_Burton/raw/refs/heads/main/ciadata.rds'
org='https://github.com/Fundamentals-Josh'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/Class_5_Burton/raw/refs/heads/main/ciadata.rds'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/Class_5_Burton/blob/main/ciadata.rds'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/Class_5_Burton/main/ciadata.rds'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/Class_5_Burton/raw/refs/heads/main/ciadata.rds'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='github.com/Fundamentals-Josh/Class_5_Burton/raw/refs/heads/main/ciadata.rds'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='github.com/Fundamentals-Josh'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/'
org='Class_5_Burton/raw/refs/heads/main'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/'
org='Class_5_Burton/raw/refs/heads/main/'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
##
str(cia)
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/'
org='Class_5_Burton/raw/refs/heads/main/'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
##
str(cia)
View(cia)
rm(list = ls())
###
git='https://github.com/Fundamentals-Josh/'
org='Class_5_Burton/raw/refs/heads/main/'
file='ciadata.rds'
gitLocation=paste0(git,org)
fullLocation=paste0(gitLocation,file)
cia=readRDS(url(fullLocation))
##
str(cia)
summary(cia$life_exp)
library(moments)
skewness(cia$life_exp)
# call the library
library(ggplot2) # do not expect an important message
# tell ggplot the data you will use
base=ggplot(data=cia) # I call it 'base'
# add the desired 'geom'
base + geom_boxplot( # you want a boxplot
aes(x=life_exp) # aes for the 'vars'
)
# this is another alternative
base + geom_histogram(aes(x=life_exp),bins = 10)
# detecting the worst case
worstCase=cia[which.min(cia$life_exp),'name']
# preparing a message
theCaption=paste("Source:CIA\n","Worst case:",worstCase)
# text for titles
theTitle='People live more than 70 years around the world'
theSubtitle="147 countries, 2023"
# time te REPLOT
box=base + geom_boxplot(aes(x=life_exp))
box + labs(title=theTitle,
subtitle = theSubtitle,
caption = theCaption,
x= 'life expectancy')
corrtable::correlation_matrix(df = cia[,-c(1,5,6)],
use = 'lower',
replace_diagonal = T)
library(ggcorrplot) # may need installation
# 1. Compute the correlation matrix
corr_matrix <- cor(cia[, c('life_exp',"infant", "maternal")])
# 2. Plot
ggcorrplot(corr_matrix)
# the H
hypo=formula(life_exp ~ infant + maternal + gini)
model <- lm(hypo, data = cia)
#then
summary(model)
library(sjPlot)
plot_models(model)
head(cia)
# version 1
base + geom_boxplot(aes(x=life_exp,y=region))
# version 2
base + geom_boxplot(aes(x=life_exp,y=reorder(region,life_exp,median)))
base+geom_boxplot(aes(x=infant,y=infant)) +
geom_boxplot(aes(x=maternal,y=maternal)) + labs(y='')
ciaLong=tidyr::pivot_longer(data=cia[,c(1,2,3,4)],
cols=!name,
names_to = "vars",
values_to = "index")
ciaLong
# then
base = ggplot(data=ciaLong)
base + geom_boxplot(aes(x=vars,y=index))
base2 = ggplot(data=ciaLong)
base2 + geom_boxplot(aes(y=index)) +
facet_wrap(~ vars, scales = "free")
base2 = ggplot(data=ciaLong)
base2 + geom_histogram(aes(x=index),bins=10) +
facet_wrap(vars~., scales = "free", ncol = 1)
# Find the value that marks the top 25% (worst)
inf_bad <- quantile(cia$infant, 0.75, na.rm = TRUE)
mat_bad   <- quantile(cia$maternal, 0.75, na.rm = TRUE)
# '1' if in the worst quartile:
cia$inf_worst <- ifelse(cia$infant >= inf_bad, 1, 0)
cia$mat_worst   <- ifelse(cia$maternal >= mat_bad, 1, 0)
# flag worst of worst
cia$worst_infmat=cia$inf_worst + cia$mat_worst
cia$worst_infmat=ifelse(cia$worst_infmat==2,T,F)
aggregate(worst_infmat ~ region, data = cia, FUN = sum, na.rm = TRUE)
inf_good <- quantile(cia$infant, 0.25, na.rm = TRUE)
mat_good   <- quantile(cia$maternal, 0.25, na.rm = TRUE)
# NOW 'less than'
cia$inf_best <- ifelse(cia$infant <= inf_good, 1, 0)
cia$mat_best   <- ifelse(cia$maternal <= mat_good, 1, 0)
# flag worst of worst
cia$best_infmat=cia$inf_best + cia$mat_best
cia$best_infmat=ifelse(cia$best_infmat==2,T,F)
aggregate(best_infmat ~ region, data = cia, FUN = sum, na.rm = TRUE)
# saving as object
counts_best <- aggregate(best_infmat ~ region, data = cia, FUN = sum)
# filtering
counts_best=counts_best[counts_best$best_infmat>0,]
# plotting
base_best=ggplot(data=counts_best)
base_best + geom_col(aes(x = reorder(region, -best_infmat),
y = best_infmat))
View(cia)
View(ciaLong)
View(corr_matrix)
View(counts_best)
View(model)
setwd("C:/Users/jjburton/Desktop/DACS 601/Week_6_Exercise_1")
rmarkdown::convert_ipynb(Homework6_Part_1.ipynb)
> rmarkdown::convert_ipynb(Homework6_Part_1.ipynb)
rmarkdown::convert_ipynb(Homework6_Part_1)
rmarkdown::convert_ipynb({
"nbformat": 4,
